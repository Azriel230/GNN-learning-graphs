{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import spektral\n",
    "import random\n",
    "import networkx as nx\n",
    "import community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cora - набор данных для обучения представлению графов (потом надо найти инфу по ней из видоса)\n",
    "spektral позволяет нам быстро загружать и предварительно обрабатывать многие стандартные наботы данных для обучения представлению графов (к примеру, Cora). Она поставляется с полезными функциями загрузки, которые позволят нам прямой доступ к таким элементам, как:\n",
    "adj - матрица смежности графа\n",
    "features - матрица функций, которая дает нам функцию в каждом из узлов\n",
    "labels - метки, обозначающие тему каждой статьи\n",
    "train_mask - массив масок: какие узлы принадлежат обучающему набору (training set)\n",
    "val_mask - массив масок: какие узлы принадлежат проверочному набору (validation set)\n",
    "test_mask - массив масок: какие узлы принадлежат тестовому набору (test set)\n",
    "\n",
    "Загружаем эти данные из набора данных 'Cora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of adj: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Type of features: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], shape=(2708, 2708), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "cora_dataset = spektral.datasets.citation.Citation(name='Cora')\n",
    "test_mask = cora_dataset.mask_te\n",
    "train_mask = cora_dataset.mask_tr\n",
    "val_mask = cora_dataset.mask_va\n",
    "graph = cora_dataset.graphs[0]\n",
    "features = graph.x\n",
    "adj = graph.a\n",
    "labels = graph.y\n",
    "\n",
    "#features = features.todense()\n",
    "adj = adj + np.eye(adj.shape[0])\n",
    "#features = features.astype('float32')\n",
    "#adj = adj.astype('float32')\n",
    "\n",
    "adj_np = np.asarray(adj, np.float32)\n",
    "adj_tf = tf.convert_to_tensor(adj_np, np.float32)\n",
    "\n",
    "features_np = np.asarray(features, np.float32)\n",
    "features_tf = tf.convert_to_tensor(features_np, np.float32)\n",
    "\n",
    "print(\"Type of adj:\", type(adj_tf))\n",
    "print(\"Type of features:\", type(features_tf))\n",
    "\n",
    "#Выведем размеры набора данных Cora\n",
    "# print(graph)\n",
    "# print(features_tf.shape)\n",
    "print(adj_tf)\n",
    "# print(labels.shape)\n",
    "\n",
    "#Выведем количество узлов в каждом наборе\n",
    "# print(np.sum(train_mask))\n",
    "# print(np.sum(val_mask))\n",
    "# print(np.sum(test_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2708\n"
     ]
    }
   ],
   "source": [
    "# Create an example EagerTensor\n",
    "x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Set elements less than or equal to 2 to 0, and elements greater than 2 to 1\n",
    "result = tf.where(x <= 2, 0, 1)\n",
    "matrix_size = adj_tf.shape[0]\n",
    "print(matrix_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опредем функцию потери перекрестной энтропии и посчета точности вычисления для конкретного набора (mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax_cross_entropy(logits, labels, mask):\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    loss *= mask\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def masked_accuracy(logits, labels, mask):\n",
    "    corrent_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy_all = tf.cast(corrent_prediction, tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    accuracy_all *= mask\n",
    "    return tf.reduce_mean(accuracy_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим слой GNN\n",
    "fts - матрица признаков узлов\n",
    "adj - матрица смежности\n",
    "transform - некоторая трансформация, которая будет применяться к каждому узлу\n",
    "activation - функция активации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn(fts, adj, transform, activation):\n",
    "    seq_fts = transform(fts) #эквивалент матрицы весов W\n",
    "    #if isinstance(adj, tf.sparse.SparseTensor):\n",
    "    #    ret_fts = tf.sparse.sparse_dense_matmul(adj, seq_fts)\n",
    "    #else:\n",
    "    ret_fts = tf.matmul(adj, seq_fts)\n",
    "    return activation(ret_fts)\n",
    "\n",
    "# def gnn(fts, adj, weights, activation):\n",
    "    \n",
    "#     # Check if adj is a sparse matrix\n",
    "#     if isinstance(adj, tf.sparse.SparseTensor):\n",
    "#         print(\"adj is a sparse matrix\")\n",
    "#     else:\n",
    "#         print(\"adj is not a sparse matrix\")\n",
    "        \n",
    "#     # Check if seq_fts is a sparse matrix\n",
    "#     if isinstance(fts, tf.sparse.SparseTensor):\n",
    "#         print(\"fts is a sparse matrix\")\n",
    "#     else:\n",
    "#         print(\"fts is not a sparse matrix\")\n",
    "\n",
    "#     if isinstance(adj, tf.sparse.SparseTensor):\n",
    "#         ret_fts = tf.sparse.sparse_dense_matmul(adj, fts)\n",
    "#     else:\n",
    "#         ret_fts = tf.matmul(adj, fts)\n",
    "\n",
    "#     print(\"Type of ret_fts = \", type(ret_fts))\n",
    "#     print(\"Type of weights = \", type(weights))\n",
    "#     return activation(tf.matmul(ret_fts, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим двуслойную GNN для обучения на данных Cora\n",
    "fts - матрица признаков узлов\n",
    "adj - матрица смежности\n",
    "gnn_fn - некоторая модель GNN \n",
    "units - количество единиц, которые будет вычислять gnn в каждом узле (сколько изменений в скрытых функциях)\n",
    "epochs - количество эпох обучения\n",
    "lr - скорость обучения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cora(fts, adj, gnn_fn, units, epochs, lr):\n",
    "    layer_1 = tf.keras.layers.Dense(units, activation=tf.nn.relu) #скрытый слой равный числу units\n",
    "    layer_2 = tf.keras.layers.Dense(7, activation=tf.nn.relu) #определяет классификацию каждого узла\n",
    "\n",
    "    def cora_gnn(fts, adj):\n",
    "        hidden = gnn_fn(fts, adj, layer_1, tf.nn.relu) #tf.nn.relu - нелинейная функция активации\n",
    "        logits = gnn_fn(hidden, adj, layer_2, tf.identity)\n",
    "        return logits\n",
    "    \n",
    "    optimazer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "    for ep in range(epochs + 1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = cora_gnn(fts, adj)\n",
    "            loss = masked_softmax_cross_entropy(logits, labels, train_mask)\n",
    "        \n",
    "        variables = tape.watched_variables()\n",
    "        grads = tape.gradient(loss, variables)\n",
    "        optimazer.apply_gradients(zip(grads, variables))\n",
    "\n",
    "        logits = cora_gnn(fts, adj)\n",
    "        val_accuracy = masked_accuracy(logits, labels, val_mask)\n",
    "        test_accuracy = masked_accuracy(logits, labels, test_mask)\n",
    "\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            print('Epoch', ep, '| Training loss:', loss.numpy(), '| Val accuracy:', val_accuracy.numpy(), '| Test accuracy:', test_accuracy.numpy())\n",
    "    return best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главный вызов обучения GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_cora(features_tf, adj_tf, gnn, 8, 500, 0.001)\n",
    "print(\"Best score = \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного изменим матрицу смежности графа, чтобы получить более устойчивую модель обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deg = tf.reduce_sum(adj_tf, axis=-1) #матрица степеней вершин графа\n",
    "# train_cora(features_tf, adj_tf / deg, gnn, 16, 500, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся методом нормализации матрицы смежности, предложенную Томасом Кипфом в сетевой модели свертки графов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_deg = tf.linalg.diag(1.0 / tf.sqrt(deg))\n",
    "# norm_adj = tf.matmul(norm_deg, tf.matmul(adj_tf, norm_deg))\n",
    "# train_cora(features_tf, norm_adj, gnn, 8, 500, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже будет описание и реализация генетического алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция инициализаци популяции. Создает список хромосом случайных весов (генов) с нормальным распределением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция инициализации популяции\n",
    "def initialize_population(size, matrix_size):\n",
    "    return [np.random.randint(0, 2, (matrix_size, matrix_size)) for _ in range(size)]\n",
    "\n",
    "def initialize_population_from_CORA(size):\n",
    "    numpy_array = adj_tf.numpy()\n",
    "    return [numpy_array for _ in range(size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фитнесс-функция. Она будет оценивать работу нейронной сети с данными весами. На вход получает хромосому - набор весов нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция оценки приспособленности\n",
    "def fitness(adjacency_matrix):\n",
    "    # Здесь должна быть функция, оценивающая работу нейронной сети с данными весами\n",
    "    # Например, можно использовать точность классификации или ошибку предсказания\n",
    "        return np.sum(adjacency_matrix) # Пример простой функции для демонстрации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[90 85 80] <class 'numpy.ndarray'>\n",
      "['C' 'B' 'E'] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "score = [70, 85, 90, 65, 80]\n",
    "population = ['A', 'B', 'C', 'D', 'E']\n",
    "k = 3\n",
    "\n",
    "print(type(population))\n",
    "\n",
    "# Step 1: Zip the score and population arrays\n",
    "zipped_data = list(zip(score, population))\n",
    "\n",
    "# Step 2: Sort the zipped array based on the score values\n",
    "sorted_data = sorted(zipped_data, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Step 3: Extract the first k elements of the sorted array\n",
    "top_k_elements = sorted_data[:k]\n",
    "\n",
    "# Step 4: Unzip the sorted array to get the desired result\n",
    "sorted_score, sorted_population = zip(*top_k_elements)\n",
    "\n",
    "np_sorted_score = np.array(sorted_score)\n",
    "np_sorted_population = np.array(sorted_population)\n",
    "print(np_sorted_score, type(np_sorted_score))\n",
    "print(np_sorted_population, type(np_sorted_population))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генетические операторы:\n",
    "Функция селекции. Отбор лучших индивидуумов. Использует оценки фитнеса для выбора k лучших хромосом.\n",
    "Функция скрещивания (кроссовера). Скрещивает двух родителей для создания двух потомков. Точка кроссовера выбирается случайно.\n",
    "Функция мутации. Мутирует хромосому, изменяя каждый ген с заданной вероятностью на значение, взятое из нормального распределения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция селекции\n",
    "def selection(population, scores, k):\n",
    "    selected_indices = np.argsort(scores)[:k]\n",
    "    # sorted_scores = np.sort(scores)[::-1]\n",
    "    # selected_indices = sorted_scores[:k]\n",
    "\n",
    "    return [population[i] for i in selected_indices]\n",
    "\n",
    "\n",
    "# def selection_connectivity(population, scores, k):\n",
    "#     # Step 1: Zip the score and population arrays\n",
    "#     zipped_data = list(zip(scores, population))\n",
    "\n",
    "#     # Step 2: Sort the zipped array based on the score values\n",
    "#     sorted_data = sorted(zipped_data, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "#     # Step 3: Extract the first k elements of the sorted array\n",
    "#     top_k_elements = sorted_data[:k]\n",
    "\n",
    "#     # Step 4: Unzip the sorted array to get the desired result\n",
    "#     sorted_score, sorted_population = zip(*top_k_elements)\n",
    "\n",
    "#     np_sorted_score = list(sorted_score)\n",
    "#     np_sorted_population = list(sorted_population)\n",
    "#     #print(sorted_score, type(np_sorted_score))\n",
    "#     #print(sorted_population, type(np_sorted_population))\n",
    "#     return np_sorted_population\n",
    "\n",
    "\n",
    "# Функция кроссовера\n",
    "# def crossover(parent1, parent2):\n",
    "#     crossover_point = random.randint(1, len(parent1) - 1)\n",
    "#     child1 = np.vstack((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "#     child2 = np.vstack((parent2[:crossover_point], parent1[crossover_point:]))\n",
    "#     return child1, child2\n",
    "def crossover(parent1, parent2):\n",
    "    crossover_point = random.randint(1, len(parent1) - 1)\n",
    "    child1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "    child2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n",
    "    return child1, child2\n",
    "\n",
    "# Функция мутации\n",
    "# def mutate(adjacency_matrix, rate):\n",
    "#     for i in range(len(adjacency_matrix)):\n",
    "#         for j in range(len(adjacency_matrix[i])):\n",
    "#             if random.random() < rate:\n",
    "#                 adjacency_matrix[i][j] = 1 - adjacency_matrix[i][j]  # Flip the value\n",
    "#     return adjacency_matrix\n",
    "def mutate(adjacency_matrix, rate):\n",
    "    mask = np.random.choice([0, 1], size=adjacency_matrix.shape, p=[1-rate, rate])\n",
    "    adjacency_matrix = np.logical_xor(adjacency_matrix, mask).astype(int)\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже представлены некоторые фитнесс функции для различных тестов ген алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Подключения\n",
    "# Фитнес-функция может оценивать матрицу смежности по количеству связей между узлами графа. Чем больше связей, тем лучше. \n",
    "\n",
    "# def connectivity_fitness(adj_matrix):\n",
    "#     graph = nx.from_numpy_array(adj_matrix)\n",
    "#     num_components = nx.number_connected_components(graph)\n",
    "#     return num_components\n",
    "\n",
    "\n",
    "def connectivity_fitness(adj_matrix):\n",
    "    graph = nx.from_numpy_array(adj_matrix)\n",
    "    num_components = nx.number_connected_components(graph)\n",
    "    return (10000 - num_components)\n",
    "\n",
    "\n",
    "# 2. Диаметр\n",
    "#Цель: свести к минимуму самый длинный и короткий путь между вершинами графа, что указывает на более компактную структуру.\n",
    "def diameter_fitness(adj_matrix):\n",
    "    # Convert adjacency matrix to a graph\n",
    "    graph = nx.from_numpy_array(adj_matrix)\n",
    "    # Calculate the diameter of the graph\n",
    "    diameter = nx.diameter(graph)\n",
    "    return diameter\n",
    "\n",
    "# 3. Разреженность\n",
    "#Цель: Поощрять разреженные графы, в которых отсутствует много ребер, что потенциально может привести к упрощению структуры.\n",
    "\n",
    "def sparsity_fitness(adj_matrix):\n",
    "    sparsity = np.count_nonzero(adj_matrix == 0) / adj_matrix.size\n",
    "    return 10 - sparsity\n",
    "\n",
    "# 4. Коэффициент кластеризации\n",
    "# Цель: Максимально увеличить средний коэффициент кластеризации по графику, что указывает на более высокую степень локальной связности.\n",
    "\n",
    "def clustering_coefficient_fitness(adj_matrix):\n",
    "    # Calculate the average clustering coefficient directly from the adjacency matrix\n",
    "    avg_clustering_coefficient = nx.average_clustering(nx.Graph(adj_matrix))\n",
    "    return avg_clustering_coefficient\n",
    "\n",
    "# 5. Модульность\n",
    "# Цель: Максимально повысить модульность, являющуюся показателем структуры сетей, для поощрения сообществ в рамках graph.\n",
    "def modularity_fitness(adj_matrix):\n",
    "    # Calculate the modularity of the graph directly from the adjacency matrix\n",
    "    graph = nx.Graph(adj_matrix)  # Create a graph from the adjacency matrix\n",
    "    partition = community.best_partition(graph)\n",
    "    modularity = community.modularity(partition, graph)\n",
    "    return modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuro_fitness(adj_matrix):\n",
    "    print(adj_matrix)\n",
    "    print(adj_matrix.shape)\n",
    "    new_adj_genetic = tf.constant(adj_matrix, dtype='float32')\n",
    "    print(type(new_adj_genetic), new_adj_genetic, new_adj_genetic.shape)\n",
    "    print(\"Fitness start\")\n",
    "    score = train_cora(features_tf, new_adj_genetic, gnn, 32, 200, 0.01)\n",
    "    print(\"Fitness end\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главная функция генетического алгоритма. Основная функция, которая управляет процессом эволюции. Инициализирует популяцию, затем в цикле для каждого поколения вычисляет фитнес, проводит отбор, скрещивание и мутацию, пока не будет достигнуто заданное количество поколений. Выводит лучший результат фитнесс-функции для каждого поколения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры алгоритма\n",
    "population_size = 4 # Размер популяции (количество хромосом в популяции)\n",
    "matrix_size = adj_tf.shape[0]   # Допустим, у нас 20 весов  # Assuming a 5x5 adjacency matrix\n",
    "num_generations = 10 # Количество поколений\n",
    "mutation_rate = 0.01 # Вероятность мутации в каждом гене\n",
    "selection_rate = 0.5 # 50% лучших переходят в следующее поколение\n",
    "\n",
    "def genetic_algorithm():\n",
    "    population = initialize_population(population_size, matrix_size)\n",
    "    #population = initialize_population_from_CORA(population_size)\n",
    "    for generation in range(num_generations):\n",
    "        #scores = [modularity_fitness(matrix) for matrix in population]\n",
    "        #scores = [sparsity_fitness(matrix) for matrix in population]\n",
    "        #scores = [clustering_coefficient_fitness(matrix) for matrix in population]\n",
    "        #scores = [connectivity_fitness(matrix) for matrix in population]\n",
    "        #scores = [diameter_fitness(matrix) for matrix in population]\n",
    "        scores = [neuro_fitness(matrix) for matrix in population]\n",
    "        print(\"score = \", scores)\n",
    "        selected = selection(population, scores, int(selection_rate * population_size))\n",
    "        next_generation = []\n",
    "        while len(next_generation) < population_size:\n",
    "            parent1, parent2 = random.sample(selected, 2)\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            next_generation.append(mutate(child1, mutation_rate))\n",
    "            #next_generation.append(child1)\n",
    "            if len(next_generation) < population_size:\n",
    "                next_generation.append(mutate(child2, mutation_rate))\n",
    "                #next_generation.append(child2)\n",
    "        population = next_generation\n",
    "        print(f\"Generation {generation + 1}, Best Score: {max(scores)}\")\n",
    "    return population\n",
    "\n",
    "# Главная функция генетического алгоритма\n",
    "# def genetic_algorithm():\n",
    "#     population = initialize_population(population_size, matrix_size)\n",
    "#     for generation in range(num_generations):\n",
    "#         #scores = [fitness(matrix) for matrix in population] #самая простая фитнесс-функция - через сумму смежностей\n",
    "#         #scores = [connectivity_fitness(matrix) for matrix in population]\n",
    "#         #scores = [diameter_fitness(matrix) for matrix in population]\n",
    "#         scores = [sparsity_fitness(matrix) for matrix in population]\n",
    "#         selected = selection(population, scores, int(selection_rate * population_size))\n",
    "#         next_generation = []\n",
    "#         while len(next_generation) < population_size:\n",
    "#             parent1, parent2 = random.sample(selected, 2)\n",
    "#             child1, child2 = crossover(parent1, parent2)\n",
    "#             next_generation.append(mutate(child1, mutation_rate))\n",
    "#             if len(next_generation) < population_size:\n",
    "#                 next_generation.append(mutate(child2, mutation_rate))\n",
    "#         population = next_generation\n",
    "#         print(\"population \", population)\n",
    "#         print(f\"Generation {generation + 1}, Best Score: {max(scores)}\")\n",
    "#     return population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главный запуск генетического алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ... 0 1 0]\n",
      " [1 0 0 ... 1 0 1]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [1 1 1 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 1]\n",
      " [1 1 0 ... 1 1 0]]\n",
      "(2708, 2708)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'> tf.Tensor(\n",
      "[[0. 1. 0. ... 0. 1. 0.]\n",
      " [1. 0. 0. ... 1. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 1.]\n",
      " [1. 1. 0. ... 1. 1. 0.]], shape=(2708, 2708), dtype=float32) (2708, 2708)\n",
      "Fitness start\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.src.activations' has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Запуск генетического алгоритма\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_population \u001b[38;5;241m=\u001b[39m \u001b[43mgenetic_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Определяем самую лучшую матрицу\u001b[39;00m\n\u001b[0;32m      5\u001b[0m scores \u001b[38;5;241m=\u001b[39m [neuro_fitness(matrix) \u001b[38;5;28;01mfor\u001b[39;00m matrix \u001b[38;5;129;01min\u001b[39;00m best_population]\n",
      "Cell \u001b[1;32mIn[26], line 17\u001b[0m, in \u001b[0;36mgenetic_algorithm\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#population = initialize_population_from_CORA(population_size)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m generation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_generations):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m#scores = [modularity_fitness(matrix) for matrix in population]\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m#scores = [sparsity_fitness(matrix) for matrix in population]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m#scores = [clustering_coefficient_fitness(matrix) for matrix in population]\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m#scores = [connectivity_fitness(matrix) for matrix in population]\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m#scores = [diameter_fitness(matrix) for matrix in population]\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mneuro_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore = \u001b[39m\u001b[38;5;124m\"\u001b[39m, scores)\n\u001b[0;32m     19\u001b[0m     selected \u001b[38;5;241m=\u001b[39m selection(population, scores, \u001b[38;5;28mint\u001b[39m(selection_rate \u001b[38;5;241m*\u001b[39m population_size))\n",
      "Cell \u001b[1;32mIn[26], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#population = initialize_population_from_CORA(population_size)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m generation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_generations):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m#scores = [modularity_fitness(matrix) for matrix in population]\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m#scores = [sparsity_fitness(matrix) for matrix in population]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m#scores = [clustering_coefficient_fitness(matrix) for matrix in population]\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m#scores = [connectivity_fitness(matrix) for matrix in population]\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m#scores = [diameter_fitness(matrix) for matrix in population]\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     scores \u001b[38;5;241m=\u001b[39m [\u001b[43mneuro_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m matrix \u001b[38;5;129;01min\u001b[39;00m population]\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore = \u001b[39m\u001b[38;5;124m\"\u001b[39m, scores)\n\u001b[0;32m     19\u001b[0m     selected \u001b[38;5;241m=\u001b[39m selection(population, scores, \u001b[38;5;28mint\u001b[39m(selection_rate \u001b[38;5;241m*\u001b[39m population_size))\n",
      "Cell \u001b[1;32mIn[25], line 7\u001b[0m, in \u001b[0;36mneuro_fitness\u001b[1;34m(adj_matrix)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(new_adj_genetic), new_adj_genetic, new_adj_genetic\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitness start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_cora\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_adj_genetic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitness end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m, in \u001b[0;36mtrain_cora\u001b[1;34m(fts, adj, gnn_fn, units, epochs, lr)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_cora\u001b[39m(fts, adj, gnn_fn, units, epochs, lr):\n\u001b[1;32m----> 2\u001b[0m     layer_1 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#скрытый слой равный числу units\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     layer_2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m7\u001b[39m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu) \u001b[38;5;66;03m#определяет классификацию каждого узла\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcora_gnn\u001b[39m(fts, adj):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:88\u001b[0m, in \u001b[0;36mDense.__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, lora_rank, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(activity_regularizer\u001b[38;5;241m=\u001b[39mactivity_regularizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m=\u001b[39m units\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m \u001b[43mactivations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(activation)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias \u001b[38;5;241m=\u001b[39m use_bias\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_initializer \u001b[38;5;241m=\u001b[39m initializers\u001b[38;5;241m.\u001b[39mget(kernel_initializer)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.src.activations' has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# Запуск генетического алгоритма\n",
    "best_population = genetic_algorithm()\n",
    "\n",
    "# Определяем самую лучшую матрицу\n",
    "scores = [neuro_fitness(matrix) for matrix in best_population]\n",
    "max_score = max(scores)\n",
    "max_index = scores.index(max_score)\n",
    "print(max_index)\n",
    "best_adj_matrix_genetic = best_population[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_adj_matrix_genetic)\n",
    "print(best_adj_matrix_genetic.shape)\n",
    "new_adj_genetic = tf.constant(best_adj_matrix_genetic, dtype='float32')\n",
    "print(type(new_adj_genetic), new_adj_genetic, new_adj_genetic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск нейросети на новой матрице смежности\n",
    "train_cora(features_tf, new_adj_genetic, gnn, 8, 500, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_cora(features_tf, new_adj_genetic, gnn, 32, 5000, 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
