{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import spektral\n",
    "import random\n",
    "import networkx as nx\n",
    "import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.4'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spektral.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cora - набор данных для обучения представлению графов (потом надо найти инфу по ней из видоса)\n",
    "spektral позволяет нам быстро загружать и предварительно обрабатывать многие стандартные наботы данных для обучения представлению графов (к примеру, Cora). Она поставляется с полезными функциями загрузки, которые позволят нам прямой доступ к таким элементам, как:\n",
    "adj - матрица смежности графа\n",
    "features - матрица функций, которая дает нам функцию в каждом из узлов\n",
    "labels - метки, обозначающие тему каждой статьи\n",
    "train_mask - массив масок: какие узлы принадлежат обучающему набору (training set)\n",
    "val_mask - массив масок: какие узлы принадлежат проверочному набору (validation set)\n",
    "test_mask - массив масок: какие узлы принадлежат тестовому набору (test set)\n",
    "\n",
    "Загружаем эти данные из набора данных 'Cora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of adj: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Type of features: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], shape=(2708, 2708), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "cora_dataset = spektral.datasets.citation.Citation(name='Cora')\n",
    "test_mask = cora_dataset.mask_te\n",
    "train_mask = cora_dataset.mask_tr\n",
    "val_mask = cora_dataset.mask_va\n",
    "graph = cora_dataset.graphs[0]\n",
    "features = graph.x\n",
    "adj = graph.a\n",
    "labels = graph.y\n",
    "\n",
    "#features = features.todense()\n",
    "adj = adj + np.eye(adj.shape[0])\n",
    "#features = features.astype('float32')\n",
    "#adj = adj.astype('float32')\n",
    "\n",
    "adj_np = np.asarray(adj, np.float32)\n",
    "adj_tf = tf.convert_to_tensor(adj_np, np.float32)\n",
    "\n",
    "features_np = np.asarray(features, np.float32)\n",
    "features_tf = tf.convert_to_tensor(features_np, np.float32)\n",
    "\n",
    "print(\"Type of adj:\", type(adj_tf))\n",
    "print(\"Type of features:\", type(features_tf))\n",
    "\n",
    "#Выведем размеры набора данных Cora\n",
    "# print(graph)\n",
    "# print(features_tf.shape)\n",
    "print(adj_tf)\n",
    "# print(labels.shape)\n",
    "\n",
    "#Выведем количество узлов в каждом наборе\n",
    "# print(np.sum(train_mask))\n",
    "# print(np.sum(val_mask))\n",
    "# print(np.sum(test_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2708\n"
     ]
    }
   ],
   "source": [
    "# Create an example EagerTensor\n",
    "x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Set elements less than or equal to 2 to 0, and elements greater than 2 to 1\n",
    "result = tf.where(x <= 2, 0, 1)\n",
    "matrix_size = adj_tf.shape[0]\n",
    "print(matrix_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опредем функцию потери перекрестной энтропии и посчета точности вычисления для конкретного набора (mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax_cross_entropy(logits, labels, mask):\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    loss *= mask\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def masked_accuracy(logits, labels, mask):\n",
    "    corrent_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy_all = tf.cast(corrent_prediction, tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    accuracy_all *= mask\n",
    "    return tf.reduce_mean(accuracy_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим слой GNN\n",
    "fts - матрица признаков узлов\n",
    "adj - матрица смежности\n",
    "transform - некоторая трансформация, которая будет применяться к каждому узлу\n",
    "activation - функция активации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn(fts, adj, transform, activation):\n",
    "    seq_fts = transform(fts) #эквивалент матрицы весов W\n",
    "    #if isinstance(adj, tf.sparse.SparseTensor):\n",
    "    #    ret_fts = tf.sparse.sparse_dense_matmul(adj, seq_fts)\n",
    "    #else:\n",
    "    ret_fts = tf.matmul(adj, seq_fts)\n",
    "    return activation(ret_fts)\n",
    "\n",
    "# def gnn(fts, adj, weights, activation):\n",
    "    \n",
    "#     # Check if adj is a sparse matrix\n",
    "#     if isinstance(adj, tf.sparse.SparseTensor):\n",
    "#         print(\"adj is a sparse matrix\")\n",
    "#     else:\n",
    "#         print(\"adj is not a sparse matrix\")\n",
    "        \n",
    "#     # Check if seq_fts is a sparse matrix\n",
    "#     if isinstance(fts, tf.sparse.SparseTensor):\n",
    "#         print(\"fts is a sparse matrix\")\n",
    "#     else:\n",
    "#         print(\"fts is not a sparse matrix\")\n",
    "\n",
    "#     if isinstance(adj, tf.sparse.SparseTensor):\n",
    "#         ret_fts = tf.sparse.sparse_dense_matmul(adj, fts)\n",
    "#     else:\n",
    "#         ret_fts = tf.matmul(adj, fts)\n",
    "\n",
    "#     print(\"Type of ret_fts = \", type(ret_fts))\n",
    "#     print(\"Type of weights = \", type(weights))\n",
    "#     return activation(tf.matmul(ret_fts, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим двуслойную GNN для обучения на данных Cora\n",
    "fts - матрица признаков узлов\n",
    "adj - матрица смежности\n",
    "gnn_fn - некоторая модель GNN \n",
    "units - количество единиц, которые будет вычислять gnn в каждом узле (сколько изменений в скрытых функциях)\n",
    "epochs - количество эпох обучения\n",
    "lr - скорость обучения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cora(fts, adj, gnn_fn, units, epochs, lr):\n",
    "    layer_1 = tf.keras.layers.Dense(units, activation=tf.nn.relu) #скрытый слой равный числу units\n",
    "    layer_2 = tf.keras.layers.Dense(7, activation=tf.nn.relu) #определяет классификацию каждого узла\n",
    "\n",
    "    def cora_gnn(fts, adj):\n",
    "        hidden = gnn_fn(fts, adj, layer_1, tf.nn.relu) #tf.nn.relu - нелинейная функция активации\n",
    "        logits = gnn_fn(hidden, adj, layer_2, tf.identity)\n",
    "        return logits\n",
    "    \n",
    "    optimazer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "    for ep in range(epochs + 1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = cora_gnn(fts, adj)\n",
    "            loss = masked_softmax_cross_entropy(logits, labels, train_mask)\n",
    "        \n",
    "        variables = tape.watched_variables()\n",
    "        grads = tape.gradient(loss, variables)\n",
    "        optimazer.apply_gradients(zip(grads, variables))\n",
    "\n",
    "        logits = cora_gnn(fts, adj)\n",
    "        val_accuracy = masked_accuracy(logits, labels, val_mask)\n",
    "        test_accuracy = masked_accuracy(logits, labels, test_mask)\n",
    "\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            print('Epoch', ep, '| Training loss:', loss.numpy(), '| Val accuracy:', val_accuracy.numpy(), '| Test accuracy:', test_accuracy.numpy())\n",
    "    \n",
    "    return best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главный вызов обучения GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Training loss: 8.739603 | Val accuracy: 0.296 | Test accuracy: 0.307\n",
      "Epoch 1 | Training loss: 7.4041333 | Val accuracy: 0.304 | Test accuracy: 0.294\n",
      "Epoch 2 | Training loss: 6.2468653 | Val accuracy: 0.318 | Test accuracy: 0.303\n",
      "Epoch 37 | Training loss: 1.5734414 | Val accuracy: 0.33199996 | Test accuracy: 0.34800002\n",
      "Epoch 38 | Training loss: 1.5638969 | Val accuracy: 0.33799997 | Test accuracy: 0.349\n",
      "Epoch 39 | Training loss: 1.5541697 | Val accuracy: 0.342 | Test accuracy: 0.35599998\n",
      "Epoch 40 | Training loss: 1.5445071 | Val accuracy: 0.344 | Test accuracy: 0.357\n",
      "Epoch 41 | Training loss: 1.5351331 | Val accuracy: 0.346 | Test accuracy: 0.36200002\n",
      "Epoch 42 | Training loss: 1.5258917 | Val accuracy: 0.348 | Test accuracy: 0.36499998\n",
      "Epoch 44 | Training loss: 1.5079205 | Val accuracy: 0.35199997 | Test accuracy: 0.369\n",
      "Epoch 46 | Training loss: 1.4908812 | Val accuracy: 0.35399997 | Test accuracy: 0.373\n",
      "Epoch 47 | Training loss: 1.4826884 | Val accuracy: 0.35799998 | Test accuracy: 0.373\n",
      "Epoch 48 | Training loss: 1.4745176 | Val accuracy: 0.36599997 | Test accuracy: 0.37399998\n",
      "Epoch 50 | Training loss: 1.4576677 | Val accuracy: 0.37199998 | Test accuracy: 0.381\n",
      "Epoch 51 | Training loss: 1.449101 | Val accuracy: 0.37399998 | Test accuracy: 0.38399997\n",
      "Epoch 53 | Training loss: 1.4319527 | Val accuracy: 0.37600002 | Test accuracy: 0.38599995\n",
      "Epoch 55 | Training loss: 1.4148406 | Val accuracy: 0.38000003 | Test accuracy: 0.38999996\n",
      "Epoch 58 | Training loss: 1.3895053 | Val accuracy: 0.38399997 | Test accuracy: 0.39999998\n",
      "Epoch 59 | Training loss: 1.3811467 | Val accuracy: 0.38999996 | Test accuracy: 0.401\n",
      "Epoch 63 | Training loss: 1.3467202 | Val accuracy: 0.39199996 | Test accuracy: 0.41\n",
      "Epoch 65 | Training loss: 1.328771 | Val accuracy: 0.39599997 | Test accuracy: 0.408\n",
      "Epoch 70 | Training loss: 1.2831684 | Val accuracy: 0.39799997 | Test accuracy: 0.41\n",
      "Epoch 71 | Training loss: 1.2739156 | Val accuracy: 0.39999998 | Test accuracy: 0.41199997\n",
      "Epoch 72 | Training loss: 1.2647368 | Val accuracy: 0.40199998 | Test accuracy: 0.41399997\n",
      "Epoch 75 | Training loss: 1.237654 | Val accuracy: 0.406 | Test accuracy: 0.42299995\n",
      "Epoch 76 | Training loss: 1.228767 | Val accuracy: 0.40999997 | Test accuracy: 0.42599997\n",
      "Epoch 77 | Training loss: 1.2199361 | Val accuracy: 0.41799995 | Test accuracy: 0.42999998\n",
      "Epoch 78 | Training loss: 1.2112253 | Val accuracy: 0.42199996 | Test accuracy: 0.429\n",
      "Epoch 79 | Training loss: 1.2025334 | Val accuracy: 0.422 | Test accuracy: 0.42799997\n",
      "Epoch 80 | Training loss: 1.1938657 | Val accuracy: 0.42799997 | Test accuracy: 0.42999998\n",
      "Epoch 82 | Training loss: 1.1771113 | Val accuracy: 0.43199998 | Test accuracy: 0.433\n",
      "Epoch 83 | Training loss: 1.1688981 | Val accuracy: 0.436 | Test accuracy: 0.433\n",
      "Epoch 89 | Training loss: 1.12217 | Val accuracy: 0.438 | Test accuracy: 0.45099995\n",
      "Epoch 90 | Training loss: 1.1148845 | Val accuracy: 0.44 | Test accuracy: 0.45499995\n",
      "Epoch 91 | Training loss: 1.1077117 | Val accuracy: 0.442 | Test accuracy: 0.45499995\n",
      "Epoch 92 | Training loss: 1.1006337 | Val accuracy: 0.444 | Test accuracy: 0.45799997\n",
      "Epoch 93 | Training loss: 1.0936737 | Val accuracy: 0.45 | Test accuracy: 0.46099997\n",
      "Epoch 95 | Training loss: 1.0802877 | Val accuracy: 0.45199996 | Test accuracy: 0.467\n",
      "Epoch 96 | Training loss: 1.0736204 | Val accuracy: 0.45599997 | Test accuracy: 0.47\n",
      "Epoch 97 | Training loss: 1.067207 | Val accuracy: 0.464 | Test accuracy: 0.467\n",
      "Best score =  <class 'tensorflow.python.framework.ops.EagerTensor'> tf.Tensor(0.464, shape=(), dtype=float32) 0.464\n"
     ]
    }
   ],
   "source": [
    "a = train_cora(features_tf, adj_tf, gnn, 8, 100, 0.001)\n",
    "value = a.numpy()\n",
    "print(\"Best score = \", type(a), a, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного изменим матрицу смежности графа, чтобы получить более устойчивую модель обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deg = tf.reduce_sum(adj_tf, axis=-1) #матрица степеней вершин графа\n",
    "# train_cora(features_tf, adj_tf / deg, gnn, 16, 500, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся методом нормализации матрицы смежности, предложенную Томасом Кипфом в сетевой модели свертки графов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_deg = tf.linalg.diag(1.0 / tf.sqrt(deg))\n",
    "# norm_adj = tf.matmul(norm_deg, tf.matmul(adj_tf, norm_deg))\n",
    "# train_cora(features_tf, norm_adj, gnn, 8, 500, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже будет описание и реализация генетического алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция инициализаци популяции. Создает список хромосом случайных весов (генов) с нормальным распределением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция инициализации популяции\n",
    "def initialize_population(size, matrix_size):\n",
    "    return [np.random.randint(0, 2, (matrix_size, matrix_size)) for _ in range(size)]\n",
    "\n",
    "def initialize_population_from_CORA(size):\n",
    "    numpy_array = adj_tf.numpy()\n",
    "    return [numpy_array for _ in range(size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фитнесс-функция. Она будет оценивать работу нейронной сети с данными весами. На вход получает хромосому - набор весов нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция оценки приспособленности\n",
    "def fitness(adjacency_matrix):\n",
    "    # Здесь должна быть функция, оценивающая работу нейронной сети с данными весами\n",
    "    # Например, можно использовать точность классификации или ошибку предсказания\n",
    "        return np.sum(adjacency_matrix) # Пример простой функции для демонстрации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[90 85 80] <class 'numpy.ndarray'>\n",
      "['C' 'B' 'E'] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "score = [70, 85, 90, 65, 80]\n",
    "population = ['A', 'B', 'C', 'D', 'E']\n",
    "k = 3\n",
    "\n",
    "print(type(population))\n",
    "\n",
    "# Step 1: Zip the score and population arrays\n",
    "zipped_data = list(zip(score, population))\n",
    "\n",
    "# Step 2: Sort the zipped array based on the score values\n",
    "sorted_data = sorted(zipped_data, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Step 3: Extract the first k elements of the sorted array\n",
    "top_k_elements = sorted_data[:k]\n",
    "\n",
    "# Step 4: Unzip the sorted array to get the desired result\n",
    "sorted_score, sorted_population = zip(*top_k_elements)\n",
    "\n",
    "np_sorted_score = np.array(sorted_score)\n",
    "np_sorted_population = np.array(sorted_population)\n",
    "print(np_sorted_score, type(np_sorted_score))\n",
    "print(np_sorted_population, type(np_sorted_population))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генетические операторы:\n",
    "Функция селекции. Отбор лучших индивидуумов. Использует оценки фитнеса для выбора k лучших хромосом.\n",
    "Функция скрещивания (кроссовера). Скрещивает двух родителей для создания двух потомков. Точка кроссовера выбирается случайно.\n",
    "Функция мутации. Мутирует хромосому, изменяя каждый ген с заданной вероятностью на значение, взятое из нормального распределения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция селекции\n",
    "def selection(population, scores, k):\n",
    "    selected_indices = np.argsort(scores)[:k]\n",
    "    # sorted_scores = np.sort(scores)[::-1]\n",
    "    # selected_indices = sorted_scores[:k]\n",
    "\n",
    "    return [population[i] for i in selected_indices]\n",
    "\n",
    "\n",
    "# def selection_connectivity(population, scores, k):\n",
    "#     # Step 1: Zip the score and population arrays\n",
    "#     zipped_data = list(zip(scores, population))\n",
    "\n",
    "#     # Step 2: Sort the zipped array based on the score values\n",
    "#     sorted_data = sorted(zipped_data, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "#     # Step 3: Extract the first k elements of the sorted array\n",
    "#     top_k_elements = sorted_data[:k]\n",
    "\n",
    "#     # Step 4: Unzip the sorted array to get the desired result\n",
    "#     sorted_score, sorted_population = zip(*top_k_elements)\n",
    "\n",
    "#     np_sorted_score = list(sorted_score)\n",
    "#     np_sorted_population = list(sorted_population)\n",
    "#     #print(sorted_score, type(np_sorted_score))\n",
    "#     #print(sorted_population, type(np_sorted_population))\n",
    "#     return np_sorted_population\n",
    "\n",
    "\n",
    "# Функция кроссовера\n",
    "# def crossover(parent1, parent2):\n",
    "#     crossover_point = random.randint(1, len(parent1) - 1)\n",
    "#     child1 = np.vstack((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "#     child2 = np.vstack((parent2[:crossover_point], parent1[crossover_point:]))\n",
    "#     return child1, child2\n",
    "def crossover(parent1, parent2):\n",
    "    crossover_point = random.randint(1, len(parent1) - 1)\n",
    "    child1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "    child2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n",
    "    return child1, child2\n",
    "\n",
    "# Функция мутации\n",
    "# def mutate(adjacency_matrix, rate):\n",
    "#     for i in range(len(adjacency_matrix)):\n",
    "#         for j in range(len(adjacency_matrix[i])):\n",
    "#             if random.random() < rate:\n",
    "#                 adjacency_matrix[i][j] = 1 - adjacency_matrix[i][j]  # Flip the value\n",
    "#     return adjacency_matrix\n",
    "def mutate(adjacency_matrix, rate):\n",
    "    mask = np.random.choice([0, 1], size=adjacency_matrix.shape, p=[1-rate, rate])\n",
    "    adjacency_matrix = np.logical_xor(adjacency_matrix, mask).astype(int)\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже представлены некоторые фитнесс функции для различных тестов ген алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Подключения\n",
    "# Фитнес-функция может оценивать матрицу смежности по количеству связей между узлами графа. Чем больше связей, тем лучше. \n",
    "\n",
    "# def connectivity_fitness(adj_matrix):\n",
    "#     graph = nx.from_numpy_array(adj_matrix)\n",
    "#     num_components = nx.number_connected_components(graph)\n",
    "#     return num_components\n",
    "\n",
    "\n",
    "def connectivity_fitness(adj_matrix):\n",
    "    graph = nx.from_numpy_array(adj_matrix)\n",
    "    num_components = nx.number_connected_components(graph)\n",
    "    return (10000 - num_components)\n",
    "\n",
    "\n",
    "# 2. Диаметр\n",
    "#Цель: свести к минимуму самый длинный и короткий путь между вершинами графа, что указывает на более компактную структуру.\n",
    "def diameter_fitness(adj_matrix):\n",
    "    # Convert adjacency matrix to a graph\n",
    "    graph = nx.from_numpy_array(adj_matrix)\n",
    "    # Calculate the diameter of the graph\n",
    "    diameter = nx.diameter(graph)\n",
    "    return diameter\n",
    "\n",
    "# 3. Разреженность\n",
    "#Цель: Поощрять разреженные графы, в которых отсутствует много ребер, что потенциально может привести к упрощению структуры.\n",
    "\n",
    "def sparsity_fitness(adj_matrix):\n",
    "    sparsity = np.count_nonzero(adj_matrix == 0) / adj_matrix.size\n",
    "    return 10 - sparsity\n",
    "\n",
    "# 4. Коэффициент кластеризации\n",
    "# Цель: Максимально увеличить средний коэффициент кластеризации по графику, что указывает на более высокую степень локальной связности.\n",
    "\n",
    "def clustering_coefficient_fitness(adj_matrix):\n",
    "    # Calculate the average clustering coefficient directly from the adjacency matrix\n",
    "    avg_clustering_coefficient = nx.average_clustering(nx.Graph(adj_matrix))\n",
    "    return avg_clustering_coefficient\n",
    "\n",
    "# 5. Модульность\n",
    "# Цель: Максимально повысить модульность, являющуюся показателем структуры сетей, для поощрения сообществ в рамках graph.\n",
    "def modularity_fitness(adj_matrix):\n",
    "    # Calculate the modularity of the graph directly from the adjacency matrix\n",
    "    graph = nx.Graph(adj_matrix)  # Create a graph from the adjacency matrix\n",
    "    partition = community.best_partition(graph)\n",
    "    modularity = community.modularity(partition, graph)\n",
    "    return modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuro_fitness(adj_matrix):\n",
    "    #print(adj_matrix)\n",
    "    #print(adj_matrix.shape)\n",
    "    new_adj_genetic = tf.constant(adj_matrix, dtype='float32')\n",
    "    #print(type(new_adj_genetic), new_adj_genetic, new_adj_genetic.shape)\n",
    "    print(\"Fitness start\")\n",
    "    score = train_cora(features_tf, new_adj_genetic, gnn, 32, 200, 0.01)\n",
    "    print(\"Fitness end\")\n",
    "    return 1 - score.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главная функция генетического алгоритма. Основная функция, которая управляет процессом эволюции. Инициализирует популяцию, затем в цикле для каждого поколения вычисляет фитнес, проводит отбор, скрещивание и мутацию, пока не будет достигнуто заданное количество поколений. Выводит лучший результат фитнесс-функции для каждого поколения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры алгоритма\n",
    "population_size = 4 # Размер популяции (количество хромосом в популяции)\n",
    "matrix_size = adj_tf.shape[0]   # Допустим, у нас 20 весов  # Assuming a 5x5 adjacency matrix\n",
    "num_generations = 5 # Количество поколений\n",
    "mutation_rate = 0.2 # Вероятность мутации в каждом гене\n",
    "selection_rate = 0.5 # 50% лучших переходят в следующее поколение\n",
    "\n",
    "def genetic_algorithm():\n",
    "    #population = initialize_population(population_size, matrix_size)\n",
    "    population = initialize_population_from_CORA(population_size)\n",
    "    for generation in range(num_generations):\n",
    "        #scores = [modularity_fitness(matrix) for matrix in population]\n",
    "        #scores = [sparsity_fitness(matrix) for matrix in population]\n",
    "        #scores = [clustering_coefficient_fitness(matrix) for matrix in population]\n",
    "        #scores = [connectivity_fitness(matrix) for matrix in population]\n",
    "        #scores = [diameter_fitness(matrix) for matrix in population]\n",
    "        scores = [neuro_fitness(matrix) for matrix in population]\n",
    "        print(\"score = \", scores)\n",
    "        selected = selection(population, scores, int(selection_rate * population_size))\n",
    "        next_generation = []\n",
    "        while len(next_generation) < population_size:\n",
    "            parent1, parent2 = random.sample(selected, 2)\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            next_generation.append(mutate(child1, mutation_rate))\n",
    "            #next_generation.append(child1)\n",
    "            if len(next_generation) < population_size:\n",
    "                next_generation.append(mutate(child2, mutation_rate))\n",
    "                #next_generation.append(child2)\n",
    "        population = next_generation\n",
    "        print(f\"Generation {generation + 1}, Best Score: {max(scores)}\")\n",
    "    return population\n",
    "\n",
    "# Главная функция генетического алгоритма\n",
    "# def genetic_algorithm():\n",
    "#     population = initialize_population(population_size, matrix_size)\n",
    "#     for generation in range(num_generations):\n",
    "#         #scores = [fitness(matrix) for matrix in population] #самая простая фитнесс-функция - через сумму смежностей\n",
    "#         #scores = [connectivity_fitness(matrix) for matrix in population]\n",
    "#         #scores = [diameter_fitness(matrix) for matrix in population]\n",
    "#         scores = [sparsity_fitness(matrix) for matrix in population]\n",
    "#         selected = selection(population, scores, int(selection_rate * population_size))\n",
    "#         next_generation = []\n",
    "#         while len(next_generation) < population_size:\n",
    "#             parent1, parent2 = random.sample(selected, 2)\n",
    "#             child1, child2 = crossover(parent1, parent2)\n",
    "#             next_generation.append(mutate(child1, mutation_rate))\n",
    "#             if len(next_generation) < population_size:\n",
    "#                 next_generation.append(mutate(child2, mutation_rate))\n",
    "#         population = next_generation\n",
    "#         print(\"population \", population)\n",
    "#         print(f\"Generation {generation + 1}, Best Score: {max(scores)}\")\n",
    "#     return population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главный запуск генетического алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness start\n",
      "Epoch 0 | Training loss: 6.5144725 | Val accuracy: 0.132 | Test accuracy: 0.12\n",
      "Epoch 2 | Training loss: 4.4338827 | Val accuracy: 0.29 | Test accuracy: 0.302\n",
      "Epoch 3 | Training loss: 1.8286716 | Val accuracy: 0.39 | Test accuracy: 0.369\n",
      "Epoch 4 | Training loss: 2.2098532 | Val accuracy: 0.474 | Test accuracy: 0.44\n",
      "Epoch 13 | Training loss: 1.3578408 | Val accuracy: 0.484 | Test accuracy: 0.48\n",
      "Epoch 14 | Training loss: 1.3171792 | Val accuracy: 0.50799996 | Test accuracy: 0.49499997\n",
      "Epoch 15 | Training loss: 1.2841762 | Val accuracy: 0.528 | Test accuracy: 0.51799995\n",
      "Epoch 16 | Training loss: 1.2688439 | Val accuracy: 0.54200006 | Test accuracy: 0.533\n",
      "Epoch 17 | Training loss: 1.2423056 | Val accuracy: 0.55399996 | Test accuracy: 0.53499997\n",
      "Epoch 18 | Training loss: 1.2173915 | Val accuracy: 0.576 | Test accuracy: 0.54599994\n",
      "Epoch 19 | Training loss: 1.1996104 | Val accuracy: 0.58 | Test accuracy: 0.568\n",
      "Epoch 20 | Training loss: 1.182602 | Val accuracy: 0.592 | Test accuracy: 0.57299995\n",
      "Epoch 21 | Training loss: 1.1652051 | Val accuracy: 0.594 | Test accuracy: 0.57899994\n",
      "Epoch 22 | Training loss: 1.151541 | Val accuracy: 0.598 | Test accuracy: 0.58199996\n",
      "Epoch 23 | Training loss: 1.1482884 | Val accuracy: 0.61 | Test accuracy: 0.594\n",
      "Epoch 24 | Training loss: 1.133773 | Val accuracy: 0.616 | Test accuracy: 0.59999996\n",
      "Epoch 27 | Training loss: 1.101995 | Val accuracy: 0.626 | Test accuracy: 0.606\n",
      "Epoch 28 | Training loss: 1.0887845 | Val accuracy: 0.63799995 | Test accuracy: 0.61899996\n",
      "Epoch 29 | Training loss: 1.0733614 | Val accuracy: 0.644 | Test accuracy: 0.622\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 6.280862 | Val accuracy: 0.274 | Test accuracy: 0.255\n",
      "Epoch 1 | Training loss: 7.8793597 | Val accuracy: 0.36799997 | Test accuracy: 0.369\n",
      "Epoch 4 | Training loss: 2.7134917 | Val accuracy: 0.47399998 | Test accuracy: 0.48899996\n",
      "Epoch 5 | Training loss: 1.7217296 | Val accuracy: 0.55799997 | Test accuracy: 0.56\n",
      "Epoch 6 | Training loss: 1.4990396 | Val accuracy: 0.576 | Test accuracy: 0.592\n",
      "Epoch 7 | Training loss: 1.5047146 | Val accuracy: 0.60400003 | Test accuracy: 0.59999996\n",
      "Epoch 9 | Training loss: 1.5171475 | Val accuracy: 0.606 | Test accuracy: 0.60499996\n",
      "Epoch 11 | Training loss: 1.3200018 | Val accuracy: 0.624 | Test accuracy: 0.6399999\n",
      "Epoch 12 | Training loss: 1.2105403 | Val accuracy: 0.626 | Test accuracy: 0.652\n",
      "Epoch 14 | Training loss: 1.0087193 | Val accuracy: 0.632 | Test accuracy: 0.65299994\n",
      "Epoch 25 | Training loss: 0.72244674 | Val accuracy: 0.636 | Test accuracy: 0.645\n",
      "Epoch 28 | Training loss: 0.69709605 | Val accuracy: 0.64 | Test accuracy: 0.652\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 6.863238 | Val accuracy: 0.38399997 | Test accuracy: 0.39299995\n",
      "Epoch 3 | Training loss: 3.6381905 | Val accuracy: 0.49199998 | Test accuracy: 0.501\n",
      "Epoch 4 | Training loss: 1.7685969 | Val accuracy: 0.494 | Test accuracy: 0.48\n",
      "Epoch 5 | Training loss: 2.2904108 | Val accuracy: 0.566 | Test accuracy: 0.557\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 5.691547 | Val accuracy: 0.121999994 | Test accuracy: 0.145\n",
      "Epoch 1 | Training loss: 10.120228 | Val accuracy: 0.17999998 | Test accuracy: 0.18999998\n",
      "Epoch 2 | Training loss: 7.0135407 | Val accuracy: 0.406 | Test accuracy: 0.41999996\n",
      "Epoch 4 | Training loss: 4.3776255 | Val accuracy: 0.45199996 | Test accuracy: 0.48\n",
      "Epoch 5 | Training loss: 2.3557932 | Val accuracy: 0.498 | Test accuracy: 0.50799996\n",
      "Epoch 6 | Training loss: 1.4833707 | Val accuracy: 0.53999996 | Test accuracy: 0.552\n",
      "Epoch 7 | Training loss: 1.1308594 | Val accuracy: 0.54999995 | Test accuracy: 0.569\n",
      "Epoch 8 | Training loss: 0.8474925 | Val accuracy: 0.598 | Test accuracy: 0.594\n",
      "Epoch 14 | Training loss: 0.5664914 | Val accuracy: 0.61 | Test accuracy: 0.632\n",
      "Epoch 15 | Training loss: 0.53468424 | Val accuracy: 0.62 | Test accuracy: 0.65\n",
      "Epoch 16 | Training loss: 0.5050527 | Val accuracy: 0.644 | Test accuracy: 0.662\n",
      "Epoch 17 | Training loss: 0.47906774 | Val accuracy: 0.65799993 | Test accuracy: 0.66400003\n",
      "Epoch 18 | Training loss: 0.45532694 | Val accuracy: 0.662 | Test accuracy: 0.6639999\n",
      "Epoch 20 | Training loss: 0.41740316 | Val accuracy: 0.668 | Test accuracy: 0.672\n",
      "Epoch 21 | Training loss: 0.39508578 | Val accuracy: 0.67399997 | Test accuracy: 0.67399997\n",
      "Epoch 22 | Training loss: 0.37363738 | Val accuracy: 0.68 | Test accuracy: 0.68299997\n",
      "Epoch 23 | Training loss: 0.3516074 | Val accuracy: 0.684 | Test accuracy: 0.686\n",
      "Epoch 28 | Training loss: 0.2570493 | Val accuracy: 0.69 | Test accuracy: 0.70399994\n",
      "Epoch 40 | Training loss: 0.14934413 | Val accuracy: 0.694 | Test accuracy: 0.72400004\n",
      "Fitness end\n",
      "score =  [0.35600000619888306, 0.36000001430511475, 0.43400001525878906, 0.3059999942779541]\n",
      "Generation 1, Best Score: 0.43400001525878906\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 16177.217 | Val accuracy: 0.072 | Test accuracy: 0.091\n",
      "Epoch 1 | Training loss: 13614.626 | Val accuracy: 0.11399999 | Test accuracy: 0.10299999\n",
      "Epoch 2 | Training loss: 46758.77 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 26996.29 | Val accuracy: 0.162 | Test accuracy: 0.149\n",
      "Epoch 3 | Training loss: 69486.02 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 14070.4 | Val accuracy: 0.072 | Test accuracy: 0.091\n",
      "Epoch 1 | Training loss: 48738.844 | Val accuracy: 0.15599999 | Test accuracy: 0.144\n",
      "Epoch 2 | Training loss: 85820.53 | Val accuracy: 0.162 | Test accuracy: 0.149\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 33335.28 | Val accuracy: 0.072 | Test accuracy: 0.091\n",
      "Epoch 1 | Training loss: 53445.453 | Val accuracy: 0.11399999 | Test accuracy: 0.10299999\n",
      "Epoch 2 | Training loss: 67648.18 | Val accuracy: 0.15599999 | Test accuracy: 0.144\n",
      "Epoch 5 | Training loss: 56847.445 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n",
      "Fitness end\n",
      "score =  [0.6840000152587891, 0.6840000152587891, 0.8379999995231628, 0.6840000152587891]\n",
      "Generation 2, Best Score: 0.8379999995231628\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 65806.984 | Val accuracy: 0.162 | Test accuracy: 0.149\n",
      "Epoch 3 | Training loss: 94974.914 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 56612.54 | Val accuracy: 0.072 | Test accuracy: 0.091\n",
      "Epoch 1 | Training loss: 219883.25 | Val accuracy: 0.121999994 | Test accuracy: 0.13\n",
      "Epoch 2 | Training loss: 177269.36 | Val accuracy: 0.15599999 | Test accuracy: 0.144\n",
      "Epoch 10 | Training loss: 63239.54 | Val accuracy: 0.162 | Test accuracy: 0.149\n",
      "Epoch 25 | Training loss: 350.60812 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 144069.98 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 34128.875 | Val accuracy: 0.121999994 | Test accuracy: 0.13\n",
      "Epoch 3 | Training loss: 83614.414 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n",
      "Fitness end\n",
      "score =  [0.6840000152587891, 0.6840000152587891, 0.6840000152587891, 0.6840000152587891]\n",
      "Generation 3, Best Score: 0.6840000152587891\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 80864.36 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 67684.016 | Val accuracy: 0.072 | Test accuracy: 0.091\n",
      "Epoch 1 | Training loss: 168507.16 | Val accuracy: 0.121999994 | Test accuracy: 0.13\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 104408.13 | Val accuracy: 0.162 | Test accuracy: 0.149\n",
      "Epoch 7 | Training loss: 160863.6 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 74351.9 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n",
      "Fitness end\n",
      "score =  [0.6840000152587891, 0.8780000060796738, 0.6840000152587891, 0.6840000152587891]\n",
      "Generation 4, Best Score: 0.8780000060796738\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 95286.39 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 210400.12 | Val accuracy: 0.11399999 | Test accuracy: 0.10299999\n",
      "Epoch 1 | Training loss: 383800.9 | Val accuracy: 0.162 | Test accuracy: 0.149\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 69579.74 | Val accuracy: 0.11399999 | Test accuracy: 0.10299999\n",
      "Epoch 2 | Training loss: 377951.2 | Val accuracy: 0.162 | Test accuracy: 0.149\n",
      "Epoch 5 | Training loss: 294551.4 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 113926.15 | Val accuracy: 0.162 | Test accuracy: 0.149\n",
      "Epoch 3 | Training loss: 182656.83 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n",
      "Epoch 82 | Training loss: 3.5509984 | Val accuracy: 0.31799996 | Test accuracy: 0.315\n",
      "Fitness end\n",
      "score =  [0.6840000152587891, 0.8379999995231628, 0.6840000152587891, 0.6820000410079956]\n",
      "Generation 5, Best Score: 0.8379999995231628\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 188492.97 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 213421.0 | Val accuracy: 0.058 | Test accuracy: 0.063999996\n",
      "Epoch 2 | Training loss: 33347.074 | Val accuracy: 0.121999994 | Test accuracy: 0.13\n",
      "Epoch 3 | Training loss: 1.9459101 | Val accuracy: 0.15599999 | Test accuracy: 0.144\n",
      "Epoch 6 | Training loss: 1.9459101 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 64067.023 | Val accuracy: 0.072 | Test accuracy: 0.091\n",
      "Epoch 1 | Training loss: 291937.7 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n",
      "Fitness end\n",
      "Fitness start\n",
      "Epoch 0 | Training loss: 28515.227 | Val accuracy: 0.15599999 | Test accuracy: 0.144\n",
      "Epoch 13 | Training loss: 1.9459101 | Val accuracy: 0.29799998 | Test accuracy: 0.31599998\n",
      "Epoch 14 | Training loss: 2.3730097 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n",
      "Fitness end\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Запуск генетического алгоритма\n",
    "best_population = genetic_algorithm()\n",
    "\n",
    "# Определяем самую лучшую матрицу\n",
    "scores = [neuro_fitness(matrix) for matrix in best_population]\n",
    "max_score = max(scores)\n",
    "max_index = scores.index(max_score)\n",
    "print(max_index)\n",
    "best_adj_matrix_genetic = best_population[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 1 0]\n",
      " ...\n",
      " [1 0 1 ... 1 1 1]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 1 1]]\n",
      "(2708, 2708)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'> tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 1. ... 1. 1. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 1. 1.]], shape=(2708, 2708), dtype=float32) (2708, 2708)\n"
     ]
    }
   ],
   "source": [
    "print(best_adj_matrix_genetic)\n",
    "print(best_adj_matrix_genetic.shape)\n",
    "new_adj_genetic = tf.constant(best_adj_matrix_genetic, dtype='float32')\n",
    "print(type(new_adj_genetic), new_adj_genetic, new_adj_genetic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Training loss: 1.9475312 | Val accuracy: 0.11399999 | Test accuracy: 0.10299999\n",
      "Epoch 10 | Training loss: 1.9459108 | Val accuracy: 0.121999994 | Test accuracy: 0.13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.121999994>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deg = tf.reduce_sum(new_adj_genetic, axis=-1) #матрица степеней вершин графа\n",
    "train_cora(features_tf, new_adj_genetic / deg, gnn, 8, 500, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Training loss: 1.9480556 | Val accuracy: 0.31599998 | Test accuracy: 0.319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.31599998>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_deg = tf.linalg.diag(1.0 / tf.sqrt(deg))\n",
    "norm_adj = tf.matmul(norm_deg, tf.matmul(new_adj_genetic, norm_deg))\n",
    "train_cora(features_tf, norm_adj, gnn, 8, 500, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запуск нейросети на новой матрице смежности\n",
    "#train_cora(features_tf, new_adj_genetic, gnn, 8, 500, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_cora(features_tf, new_adj_genetic, gnn, 32, 5000, 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
