{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import spektral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cora - набор данных для обучения представлению графов (потом надо найти инфу по ней из видоса)\n",
    "spektral позволяет нам быстро загружать и предварительно обрабатывать многие стандартные наботы данных для обучения представлению графов (к примеру, Cora). Она поставляется с полезными функциями загрузки, которые позволят нам прямой доступ к таким элементам, как:\n",
    "adj - матрица смежности графа\n",
    "features - матрица функций, которая дает нам функцию в каждом из узлов\n",
    "labels - метки, обозначающие тему каждой статьи\n",
    "train_mask - массив масок: какие узлы принадлежат обучающему набору (training set)\n",
    "val_mask - массив масок: какие узлы принадлежат проверочному набору (validation set)\n",
    "test_mask - массив масок: какие узлы принадлежат тестовому набору (test set)\n",
    "\n",
    "Загружаем эти данные из набора данных 'Cora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(n_nodes=2708, n_node_features=1433, n_edge_features=None, n_labels=7)\n",
      "(2708, 1433)\n",
      "(2708, 2708)\n",
      "(2708, 7)\n",
      "140\n",
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "cora_dataset = spektral.datasets.citation.Citation(name='Cora')\n",
    "test_mask = cora_dataset.mask_te\n",
    "train_mask = cora_dataset.mask_tr\n",
    "val_mask = cora_dataset.mask_va\n",
    "graph = cora_dataset.graphs[0]\n",
    "features = graph.x\n",
    "adj = graph.a\n",
    "labels = graph.y\n",
    "\n",
    "#features = features.todense()\n",
    "#adj = adj + np.eye(adj.shape[0])\n",
    "features = features.astype('float32')\n",
    "adj = adj.astype('float32')\n",
    "\n",
    "#Выведем размеры набора данных Cora\n",
    "print(graph)\n",
    "print(features.shape)\n",
    "print(adj.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "#Выведем количество узлов в каждом наборе\n",
    "print(np.sum(train_mask))\n",
    "print(np.sum(val_mask))\n",
    "print(np.sum(test_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опредем функцию потери перекрестной энтропии и посчета точности вычисления для конкретного набора (mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax_cross_entropy(logits, labels, mask):\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logist=logits, labels=labels)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    loss *= mask\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def masked_accuracy(logits, labels, mask):\n",
    "    corrent_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy_all = tf.cast(corrent_prediction, tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    accuracy_all *= mask\n",
    "    return tf.reduce_mean(accuracy_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим слой GNN\n",
    "fts - матрица признаков узлов\n",
    "adj - матрица смежности\n",
    "transform - некоторая трансформация, которая будет применяться к каждому узлу\n",
    "activation - функция активации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn(fts, adj, transform, activation):\n",
    "    seq_fts = transform(fts) #эквивалент матрицы весов W\n",
    "    ret_fts = tf.matmul(adj, seq_fts)\n",
    "    return activation(ret_fts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим двуслойную GNN для обучения на данных Cora\n",
    "fts - матрица признаков узлов\n",
    "adj - матрица смежности\n",
    "gnn_fn - некоторая модель GNN \n",
    "units - количество единиц, которые будет вычислять gnn в каждом узле (сколько изменений в скрытых функциях)\n",
    "epochs - количество эпох обучения\n",
    "lr - скорость обучения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cora(fts, adj, gnn_fn, units, epochs, lr):\n",
    "    layer_1 = tf.keras.layers.Dense(units) #скрытый слой равный числу units\n",
    "    layer_2 = tf.keras.layers.Dense(7) #определяет классификацию каждого узла\n",
    "\n",
    "    def cora_gnn(fts, adj):\n",
    "        hidden = gnn_fn(fts, adj, layer_1, tf.nn.relu) #tf.nn.relu - нелинейная функция активации\n",
    "        logits = gnn_fn(hidden, adj, layer_2, tf.identity)\n",
    "        return logits\n",
    "    \n",
    "    optimazer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "    for ep in range(epochs + 1):\n",
    "        with tf.GradientTape() as t:\n",
    "            print(\"debug: \", fts, adj)\n",
    "            logits = cora_gnn(fts, adj)\n",
    "            loss = masked_softmax_cross_entropy(logits, labels, train_mask)\n",
    "        \n",
    "        variables = t.watched_variables()\n",
    "        grads = t.gradient(loss, variables)\n",
    "        optimazer.apply_gradients(zip(grads, variables))\n",
    "\n",
    "        logits = cora_gnn(fts, adj)\n",
    "        val_accuracy = masked_accuracy(logits, labels, val_mask)\n",
    "        test_accuracy = masked_accuracy(logits, labels, test_mask)\n",
    "\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            print('Epoch', ep, '| Training loss:', loss.numpy(), '| Val accuracy:', val_accuracy.numpy(), '| Test accuracy:', test_accuracy.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главный вызов обучения GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]   (0, 633)\t1.0\n",
      "  (0, 1862)\t1.0\n",
      "  (0, 2582)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (1, 652)\t1.0\n",
      "  (1, 654)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (2, 332)\t1.0\n",
      "  (2, 1454)\t1.0\n",
      "  (2, 1666)\t1.0\n",
      "  (2, 1986)\t1.0\n",
      "  (3, 2544)\t1.0\n",
      "  (4, 1016)\t1.0\n",
      "  (4, 1256)\t1.0\n",
      "  (4, 1761)\t1.0\n",
      "  (4, 2175)\t1.0\n",
      "  (4, 2176)\t1.0\n",
      "  (5, 1629)\t1.0\n",
      "  (5, 1659)\t1.0\n",
      "  (5, 2546)\t1.0\n",
      "  (6, 373)\t1.0\n",
      "  (6, 1042)\t1.0\n",
      "  (6, 1416)\t1.0\n",
      "  (6, 1602)\t1.0\n",
      "  (7, 208)\t1.0\n",
      "  :\t:\n",
      "  (2694, 431)\t1.0\n",
      "  (2694, 2695)\t1.0\n",
      "  (2695, 431)\t1.0\n",
      "  (2695, 2694)\t1.0\n",
      "  (2696, 2615)\t1.0\n",
      "  (2697, 986)\t1.0\n",
      "  (2698, 1400)\t1.0\n",
      "  (2698, 1573)\t1.0\n",
      "  (2699, 2630)\t1.0\n",
      "  (2700, 1151)\t1.0\n",
      "  (2701, 44)\t1.0\n",
      "  (2701, 2624)\t1.0\n",
      "  (2702, 186)\t1.0\n",
      "  (2702, 1536)\t1.0\n",
      "  (2703, 1298)\t1.0\n",
      "  (2704, 641)\t1.0\n",
      "  (2705, 287)\t1.0\n",
      "  (2706, 165)\t1.0\n",
      "  (2706, 169)\t1.0\n",
      "  (2706, 1473)\t1.0\n",
      "  (2706, 2707)\t1.0\n",
      "  (2707, 165)\t1.0\n",
      "  (2707, 598)\t1.0\n",
      "  (2707, 1473)\t1.0\n",
      "  (2707, 2706)\t1.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "TypeError: sparse array length is ambiguous; use getnnz() or shape[0]\nTraceback (most recent call last):\n\n  File \"c:\\Users\\leshk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\_base.py\", line 404, in __len__\n    raise TypeError(\"sparse array length is ambiguous; use getnnz()\"\n\nTypeError: sparse array length is ambiguous; use getnnz() or shape[0]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_cora\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[50], line 16\u001b[0m, in \u001b[0;36mtrain_cora\u001b[1;34m(fts, adj, gnn_fn, units, epochs, lr)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdebug: \u001b[39m\u001b[38;5;124m\"\u001b[39m, fts, adj)\n\u001b[1;32m---> 16\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mcora_gnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m masked_softmax_cross_entropy(logits, labels, train_mask)\n\u001b[0;32m     19\u001b[0m variables \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "Cell \u001b[1;32mIn[50], line 6\u001b[0m, in \u001b[0;36mtrain_cora.<locals>.cora_gnn\u001b[1;34m(fts, adj)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcora_gnn\u001b[39m(fts, adj):\n\u001b[1;32m----> 6\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[43mgnn_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#tf.nn.relu - нелинейная функция активации\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     logits \u001b[38;5;241m=\u001b[39m gnn_fn(hidden, adj, layer_2, tf\u001b[38;5;241m.\u001b[39midentity)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "Cell \u001b[1;32mIn[49], line 3\u001b[0m, in \u001b[0;36mgnn\u001b[1;34m(fts, adj, transform, activation)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgnn\u001b[39m(fts, adj, transform, activation):\n\u001b[0;32m      2\u001b[0m     seq_fts \u001b[38;5;241m=\u001b[39m transform(fts) \u001b[38;5;66;03m#эквивалент матрицы весов W\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     ret_fts \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_fts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m activation(ret_fts)\n",
      "File \u001b[1;32mc:\\Users\\leshk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32mc:\\Users\\leshk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\leshk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: TypeError: sparse array length is ambiguous; use getnnz() or shape[0]\nTraceback (most recent call last):\n\n  File \"c:\\Users\\leshk\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\_base.py\", line 404, in __len__\n    raise TypeError(\"sparse array length is ambiguous; use getnnz()\"\n\nTypeError: sparse array length is ambiguous; use getnnz() or shape[0]\n\n"
     ]
    }
   ],
   "source": [
    "train_cora(features, adj, gnn, 32, 200, 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
