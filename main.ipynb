{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import spektral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cora - набор данных для обучения представлению графов (потом надо найти инфу по ней из видоса)\n",
    "spektral позволяет нам быстро загружать и предварительно обрабатывать многие стандартные наботы данных для обучения представлению графов (к примеру, Cora). Она поставляется с полезными функциями загрузки, которые позволят нам прямой доступ к таким элементам, как:\n",
    "adj - матрица смежности графа\n",
    "features - матрица функций, которая дает нам функцию в каждом из узлов\n",
    "labels - метки, обозначающие тему каждой статьи\n",
    "train_mask - массив масок: какие узлы принадлежат обучающему набору (training set)\n",
    "val_mask - массив масок: какие узлы принадлежат проверочному набору (validation set)\n",
    "test_mask - массив масок: какие узлы принадлежат тестовому набору (test set)\n",
    "\n",
    "Загружаем эти данные из набора данных 'Cora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of adj: <class 'numpy.ndarray'>\n",
      "Type of features: <class 'numpy.ndarray'>\n",
      "Graph(n_nodes=2708, n_node_features=1433, n_edge_features=None, n_labels=7)\n",
      "(2708, 1433)\n",
      "(2708, 2708)\n",
      "(2708, 7)\n",
      "140\n",
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "cora_dataset = spektral.datasets.citation.Citation(name='Cora')\n",
    "test_mask = cora_dataset.mask_te\n",
    "train_mask = cora_dataset.mask_tr\n",
    "val_mask = cora_dataset.mask_va\n",
    "graph = cora_dataset.graphs[0]\n",
    "features = graph.x\n",
    "adj = graph.a\n",
    "labels = graph.y\n",
    "\n",
    "#features = features.todense()\n",
    "adj = adj + np.eye(adj.shape[0])\n",
    "features = features.astype('float32')\n",
    "adj = adj.astype('float32')\n",
    "\n",
    "print(\"Type of adj:\", type(adj))\n",
    "print(\"Type of features:\", type(features))\n",
    "\n",
    "#Выведем размеры набора данных Cora\n",
    "print(graph)\n",
    "print(features.shape)\n",
    "print(adj.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "#Выведем количество узлов в каждом наборе\n",
    "print(np.sum(train_mask))\n",
    "print(np.sum(val_mask))\n",
    "print(np.sum(test_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опредем функцию потери перекрестной энтропии и посчета точности вычисления для конкретного набора (mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax_cross_entropy(logits, labels, mask):\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logist=logits, labels=labels)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    loss *= mask\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def masked_accuracy(logits, labels, mask):\n",
    "    corrent_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy_all = tf.cast(corrent_prediction, tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    accuracy_all *= mask\n",
    "    return tf.reduce_mean(accuracy_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим слой GNN\n",
    "fts - матрица признаков узлов\n",
    "adj - матрица смежности\n",
    "transform - некоторая трансформация, которая будет применяться к каждому узлу\n",
    "activation - функция активации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gnn(fts, adj, transform, activation):\n",
    "#     seq_fts = transform(fts) #эквивалент матрицы весов W\n",
    "#     if isinstance(adj, tf.sparse.SparseTensor):\n",
    "#         ret_fts = tf.sparse.sparse_dense_matmul(adj, seq_fts)\n",
    "#     else:\n",
    "#         ret_fts = tf.matmul(adj, seq_fts)\n",
    "#     return activation(ret_fts)\n",
    "def gnn(fts, adj, weights, activation):\n",
    "    \n",
    "    # Check if adj is a sparse matrix\n",
    "    if isinstance(adj, tf.sparse.SparseTensor):\n",
    "        print(\"adj is a sparse matrix\")\n",
    "    else:\n",
    "        print(\"adj is not a sparse matrix\")\n",
    "        \n",
    "    # Check if seq_fts is a sparse matrix\n",
    "    if isinstance(fts, tf.sparse.SparseTensor):\n",
    "        print(\"fts is a sparse matrix\")\n",
    "    else:\n",
    "        print(\"fts is not a sparse matrix\")\n",
    "\n",
    "    if isinstance(adj, tf.sparse.SparseTensor):\n",
    "        ret_fts = tf.sparse.sparse_dense_matmul(adj, fts)\n",
    "    else:\n",
    "        ret_fts = tf.matmul(adj, fts)\n",
    "    return activation(tf.matmul(ret_fts, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим двуслойную GNN для обучения на данных Cora\n",
    "fts - матрица признаков узлов\n",
    "adj - матрица смежности\n",
    "gnn_fn - некоторая модель GNN \n",
    "units - количество единиц, которые будет вычислять gnn в каждом узле (сколько изменений в скрытых функциях)\n",
    "epochs - количество эпох обучения\n",
    "lr - скорость обучения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cora(fts, adj, gnn_fn, units, epochs, lr):\n",
    "    layer_1 = tf.keras.layers.Dense(units, activation=tf.nn.relu) #скрытый слой равный числу units\n",
    "    layer_2 = tf.keras.layers.Dense(7, activation=tf.nn.relu) #определяет классификацию каждого узла\n",
    "\n",
    "    def cora_gnn(fts, adj):\n",
    "        hidden = gnn_fn(fts, adj, layer_1, tf.nn.relu) #tf.nn.relu - нелинейная функция активации\n",
    "        logits = gnn_fn(hidden, adj, layer_2, tf.identity)\n",
    "        return logits\n",
    "    \n",
    "    optimazer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "    for ep in range(epochs + 1):\n",
    "        with tf.GradientTape() as t:\n",
    "            print(\"debug: \", fts, adj)\n",
    "            logits = cora_gnn(fts, adj)\n",
    "            loss = masked_softmax_cross_entropy(logits, labels, train_mask)\n",
    "        \n",
    "        variables = t.watched_variables()\n",
    "        grads = t.gradient(loss, variables)\n",
    "        optimazer.apply_gradients(zip(grads, variables))\n",
    "\n",
    "        logits = cora_gnn(fts, adj)\n",
    "        val_accuracy = masked_accuracy(logits, labels, val_mask)\n",
    "        test_accuracy = masked_accuracy(logits, labels, test_mask)\n",
    "\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            print('Epoch', ep, '| Training loss:', loss.numpy(), '| Val accuracy:', val_accuracy.numpy(), '| Test accuracy:', test_accuracy.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главный вызов обучения GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] [[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]]\n",
      "adj is not a sparse matrix\n",
      "fts is not a sparse matrix\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (<Dense name=dense_8, built=False>) with an unsupported type (<class 'keras.src.layers.core.dense.Dense'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_cora\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[38], line 16\u001b[0m, in \u001b[0;36mtrain_cora\u001b[1;34m(fts, adj, gnn_fn, units, epochs, lr)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdebug: \u001b[39m\u001b[38;5;124m\"\u001b[39m, fts, adj)\n\u001b[1;32m---> 16\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mcora_gnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m masked_softmax_cross_entropy(logits, labels, train_mask)\n\u001b[0;32m     19\u001b[0m variables \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "Cell \u001b[1;32mIn[38], line 6\u001b[0m, in \u001b[0;36mtrain_cora.<locals>.cora_gnn\u001b[1;34m(fts, adj)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcora_gnn\u001b[39m(fts, adj):\n\u001b[1;32m----> 6\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[43mgnn_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#tf.nn.relu - нелинейная функция активации\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     logits \u001b[38;5;241m=\u001b[39m gnn_fn(hidden, adj, layer_2, tf\u001b[38;5;241m.\u001b[39midentity)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "Cell \u001b[1;32mIn[37], line 26\u001b[0m, in \u001b[0;36mgnn\u001b[1;34m(fts, adj, weights, activation)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     ret_fts \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmatmul(adj, fts)\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m activation(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret_fts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\framework\\constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Attempt to convert a value (<Dense name=dense_8, built=False>) with an unsupported type (<class 'keras.src.layers.core.dense.Dense'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "train_cora(features, adj, gnn, 32, 200, 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
