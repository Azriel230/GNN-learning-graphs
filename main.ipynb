{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import spektral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cora - набор данных для обучения представлению графов (потом надо найти инфу по ней из видоса)\n",
    "spektral позволяет нам быстро загружать и предварительно обрабатывать многие стандартные наботы данных для обучения представлению графов (к примеру, Cora). Она поставляется с полезными функциями загрузки, которые позволят нам прямой доступ к таким элементам, как:\n",
    "adj - матрица смежности графа\n",
    "features - матрица функций, которая дает нам функцию в каждом из узлов\n",
    "labels - метки, обозначающие тему каждой статьи\n",
    "train_mask - массив масок: какие узлы принадлежат обучающему набору (training set)\n",
    "val_mask - массив масок: какие узлы принадлежат проверочному набору (validation set)\n",
    "test_mask - массив масок: какие узлы принадлежат тестовому набору (test set)\n",
    "\n",
    "Загружаем эти данные из набора данных 'Cora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of adj: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Type of features: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Graph(n_nodes=2708, n_node_features=1433, n_edge_features=None, n_labels=7)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(2708, 1433), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 1.]], shape=(2708, 2708), dtype=float32)\n",
      "(2708, 7)\n",
      "140\n",
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "cora_dataset = spektral.datasets.citation.Citation(name='Cora')\n",
    "test_mask = cora_dataset.mask_te\n",
    "train_mask = cora_dataset.mask_tr\n",
    "val_mask = cora_dataset.mask_va\n",
    "graph = cora_dataset.graphs[0]\n",
    "features = graph.x\n",
    "adj = graph.a\n",
    "labels = graph.y\n",
    "\n",
    "#features = features.todense()\n",
    "adj = adj + np.eye(adj.shape[0])\n",
    "#features = features.astype('float32')\n",
    "#adj = adj.astype('float32')\n",
    "\n",
    "adj_np = np.asarray(adj, np.float32)\n",
    "adj_tf = tf.convert_to_tensor(adj_np, np.float32)\n",
    "\n",
    "features_np = np.asarray(features, np.float32)\n",
    "features_tf = tf.convert_to_tensor(features_np, np.float32)\n",
    "\n",
    "print(\"Type of adj:\", type(adj_tf))\n",
    "print(\"Type of features:\", type(features_tf))\n",
    "\n",
    "#Выведем размеры набора данных Cora\n",
    "print(graph)\n",
    "print(features_tf.shape)\n",
    "print(adj_tf.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "#Выведем количество узлов в каждом наборе\n",
    "print(np.sum(train_mask))\n",
    "print(np.sum(val_mask))\n",
    "print(np.sum(test_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опредем функцию потери перекрестной энтропии и посчета точности вычисления для конкретного набора (mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax_cross_entropy(logits, labels, mask):\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    loss *= mask\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def masked_accuracy(logits, labels, mask):\n",
    "    corrent_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy_all = tf.cast(corrent_prediction, tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    accuracy_all *= mask\n",
    "    return tf.reduce_mean(accuracy_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим слой GNN\n",
    "fts - матрица признаков узлов\n",
    "adj - матрица смежности\n",
    "transform - некоторая трансформация, которая будет применяться к каждому узлу\n",
    "activation - функция активации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn(fts, adj, transform, activation):\n",
    "    seq_fts = transform(fts) #эквивалент матрицы весов W\n",
    "    #if isinstance(adj, tf.sparse.SparseTensor):\n",
    "    #    ret_fts = tf.sparse.sparse_dense_matmul(adj, seq_fts)\n",
    "    #else:\n",
    "    ret_fts = tf.matmul(adj, seq_fts)\n",
    "    return activation(ret_fts)\n",
    "\n",
    "# def gnn(fts, adj, weights, activation):\n",
    "    \n",
    "#     # Check if adj is a sparse matrix\n",
    "#     if isinstance(adj, tf.sparse.SparseTensor):\n",
    "#         print(\"adj is a sparse matrix\")\n",
    "#     else:\n",
    "#         print(\"adj is not a sparse matrix\")\n",
    "        \n",
    "#     # Check if seq_fts is a sparse matrix\n",
    "#     if isinstance(fts, tf.sparse.SparseTensor):\n",
    "#         print(\"fts is a sparse matrix\")\n",
    "#     else:\n",
    "#         print(\"fts is not a sparse matrix\")\n",
    "\n",
    "#     if isinstance(adj, tf.sparse.SparseTensor):\n",
    "#         ret_fts = tf.sparse.sparse_dense_matmul(adj, fts)\n",
    "#     else:\n",
    "#         ret_fts = tf.matmul(adj, fts)\n",
    "\n",
    "#     print(\"Type of ret_fts = \", type(ret_fts))\n",
    "#     print(\"Type of weights = \", type(weights))\n",
    "#     return activation(tf.matmul(ret_fts, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим двуслойную GNN для обучения на данных Cora\n",
    "fts - матрица признаков узлов\n",
    "adj - матрица смежности\n",
    "gnn_fn - некоторая модель GNN \n",
    "units - количество единиц, которые будет вычислять gnn в каждом узле (сколько изменений в скрытых функциях)\n",
    "epochs - количество эпох обучения\n",
    "lr - скорость обучения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cora(fts, adj, gnn_fn, units, epochs, lr):\n",
    "    layer_1 = tf.keras.layers.Dense(units, activation=tf.nn.relu) #скрытый слой равный числу units\n",
    "    layer_2 = tf.keras.layers.Dense(7, activation=tf.nn.relu) #определяет классификацию каждого узла\n",
    "\n",
    "    def cora_gnn(fts, adj):\n",
    "        hidden = gnn_fn(fts, adj, layer_1, tf.nn.relu) #tf.nn.relu - нелинейная функция активации\n",
    "        logits = gnn_fn(hidden, adj, layer_2, tf.identity)\n",
    "        return logits\n",
    "    \n",
    "    optimazer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "    for ep in range(epochs + 1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = cora_gnn(fts, adj)\n",
    "            loss = masked_softmax_cross_entropy(logits, labels, train_mask)\n",
    "        \n",
    "        variables = tape.watched_variables()\n",
    "        grads = tape.gradient(loss, variables)\n",
    "        optimazer.apply_gradients(zip(grads, variables))\n",
    "\n",
    "        logits = cora_gnn(fts, adj)\n",
    "        val_accuracy = masked_accuracy(logits, labels, val_mask)\n",
    "        test_accuracy = masked_accuracy(logits, labels, test_mask)\n",
    "\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            print('Epoch', ep, '| Training loss:', loss.numpy(), '| Val accuracy:', val_accuracy.numpy(), '| Test accuracy:', test_accuracy.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главный вызов обучения GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Training loss: 4.646867 | Val accuracy: 0.34999996 | Test accuracy: 0.352\n",
      "Epoch 4 | Training loss: 3.7570548 | Val accuracy: 0.364 | Test accuracy: 0.355\n",
      "Epoch 5 | Training loss: 2.4916403 | Val accuracy: 0.528 | Test accuracy: 0.50600004\n",
      "Epoch 6 | Training loss: 1.584272 | Val accuracy: 0.618 | Test accuracy: 0.595\n",
      "Epoch 7 | Training loss: 1.2613305 | Val accuracy: 0.634 | Test accuracy: 0.631\n",
      "Epoch 8 | Training loss: 1.154107 | Val accuracy: 0.65 | Test accuracy: 0.65599996\n",
      "Epoch 9 | Training loss: 1.0506023 | Val accuracy: 0.666 | Test accuracy: 0.67399997\n",
      "Epoch 10 | Training loss: 0.9747684 | Val accuracy: 0.684 | Test accuracy: 0.69899994\n",
      "Epoch 12 | Training loss: 0.8535274 | Val accuracy: 0.69 | Test accuracy: 0.70799994\n",
      "Epoch 13 | Training loss: 0.7868511 | Val accuracy: 0.69200003 | Test accuracy: 0.714\n",
      "Epoch 14 | Training loss: 0.7217266 | Val accuracy: 0.694 | Test accuracy: 0.706\n",
      "Epoch 21 | Training loss: 0.5119682 | Val accuracy: 0.696 | Test accuracy: 0.705\n",
      "Epoch 22 | Training loss: 0.48894894 | Val accuracy: 0.708 | Test accuracy: 0.705\n",
      "Epoch 23 | Training loss: 0.47220692 | Val accuracy: 0.71199995 | Test accuracy: 0.70799994\n",
      "Epoch 24 | Training loss: 0.45902756 | Val accuracy: 0.716 | Test accuracy: 0.71099997\n",
      "Epoch 27 | Training loss: 0.4420495 | Val accuracy: 0.718 | Test accuracy: 0.714\n",
      "Epoch 29 | Training loss: 0.42061254 | Val accuracy: 0.722 | Test accuracy: 0.718\n",
      "Epoch 44 | Training loss: 0.35128316 | Val accuracy: 0.726 | Test accuracy: 0.716\n",
      "Epoch 47 | Training loss: 0.34488347 | Val accuracy: 0.732 | Test accuracy: 0.717\n",
      "Epoch 59 | Training loss: 0.3271714 | Val accuracy: 0.73599994 | Test accuracy: 0.72400004\n",
      "Epoch 60 | Training loss: 0.32541057 | Val accuracy: 0.738 | Test accuracy: 0.72400004\n",
      "Epoch 64 | Training loss: 0.31892005 | Val accuracy: 0.73800004 | Test accuracy: 0.726\n"
     ]
    }
   ],
   "source": [
    "train_cora(features_tf, adj_tf, gnn, 32, 200, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного изменим матрицу смежности графа, чтобы получить более устойчивую модель обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Training loss: 1.9445586 | Val accuracy: 0.22599998 | Test accuracy: 0.213\n",
      "Epoch 1 | Training loss: 1.830808 | Val accuracy: 0.35199997 | Test accuracy: 0.358\n",
      "Epoch 2 | Training loss: 1.6829454 | Val accuracy: 0.45199996 | Test accuracy: 0.465\n",
      "Epoch 3 | Training loss: 1.5160421 | Val accuracy: 0.516 | Test accuracy: 0.53\n",
      "Epoch 4 | Training loss: 1.3495936 | Val accuracy: 0.59 | Test accuracy: 0.607\n",
      "Epoch 5 | Training loss: 1.1923124 | Val accuracy: 0.644 | Test accuracy: 0.67399997\n",
      "Epoch 6 | Training loss: 1.04554 | Val accuracy: 0.686 | Test accuracy: 0.70799994\n",
      "Epoch 7 | Training loss: 0.91327184 | Val accuracy: 0.69 | Test accuracy: 0.717\n",
      "Epoch 8 | Training loss: 0.79829204 | Val accuracy: 0.702 | Test accuracy: 0.733\n",
      "Epoch 9 | Training loss: 0.7007021 | Val accuracy: 0.70600003 | Test accuracy: 0.745\n",
      "Epoch 10 | Training loss: 0.61963934 | Val accuracy: 0.71199995 | Test accuracy: 0.747\n"
     ]
    }
   ],
   "source": [
    "deg = tf.reduce_sum(adj_tf, axis=-1) #матрица степеней вершин графа\n",
    "train_cora(features_tf, adj_tf / deg, gnn, 32, 200, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся методом нормализации матрицы смежности, предложенную Томасом Кипфом в сетевой модели свертки графов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Training loss: 1.9538654 | Val accuracy: 0.37199998 | Test accuracy: 0.38199997\n",
      "Epoch 1 | Training loss: 1.8432275 | Val accuracy: 0.422 | Test accuracy: 0.431\n",
      "Epoch 2 | Training loss: 1.7182083 | Val accuracy: 0.50600004 | Test accuracy: 0.50999993\n",
      "Epoch 3 | Training loss: 1.5649697 | Val accuracy: 0.604 | Test accuracy: 0.58299994\n",
      "Epoch 4 | Training loss: 1.3862036 | Val accuracy: 0.656 | Test accuracy: 0.657\n",
      "Epoch 5 | Training loss: 1.1970687 | Val accuracy: 0.72199994 | Test accuracy: 0.709\n",
      "Epoch 6 | Training loss: 1.0130662 | Val accuracy: 0.736 | Test accuracy: 0.73899996\n",
      "Epoch 7 | Training loss: 0.84018743 | Val accuracy: 0.754 | Test accuracy: 0.754\n",
      "Epoch 8 | Training loss: 0.6831143 | Val accuracy: 0.77 | Test accuracy: 0.76400006\n",
      "Epoch 9 | Training loss: 0.5458493 | Val accuracy: 0.77199996 | Test accuracy: 0.7839999\n",
      "Epoch 10 | Training loss: 0.42996103 | Val accuracy: 0.78 | Test accuracy: 0.7929999\n",
      "Epoch 13 | Training loss: 0.20034412 | Val accuracy: 0.782 | Test accuracy: 0.79599994\n",
      "Epoch 14 | Training loss: 0.15332197 | Val accuracy: 0.7879999 | Test accuracy: 0.79599994\n"
     ]
    }
   ],
   "source": [
    "norm_deg = tf.linalg.diag(1.0 / tf.sqrt(deg))\n",
    "norm_adj = tf.matmul(norm_deg, tf.matmul(adj_tf, norm_deg))\n",
    "train_cora(features_tf, norm_adj, gnn, 32, 200, 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
